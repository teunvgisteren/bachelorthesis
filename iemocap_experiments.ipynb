{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4366cadf-14c7-4ef5-be32-0a3e8a3b785b",
   "metadata": {},
   "source": [
    "### Experiments From \"Filtered Feelings: Investigating Frequency Filters in Speech Emotion Recognition Models\"\n",
    "Created by: Teun van Gisteren (s1055104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ff50f-1322-4f1e-a159-04a4b46b1267",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8b432-90b3-40ed-94ad-00c2f4814b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This cell might return an \"TypeError: 'type' object is not subscriptable\" error. If you run the cell again it should work.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt\n",
    "from os import mkdir\n",
    "from os import makedirs\n",
    "from os.path import isdir \n",
    "import shutil\n",
    "from scipy.signal import spectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from speechbrain.inference.interfaces import foreign_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e58e81-5c99-4edc-bb00-6fc2b5a8130c",
   "metadata": {},
   "source": [
    "# 5.3 IEMOCAP Data Handling & 5.4 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98105394-a8a4-4ad0-a0f1-c0d5bd9508e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iemocap_location = None # The IEMOCAP_full_release folder\n",
    "results_location = None # Where you want the results .csv files to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7118e-e618-45fd-b0cc-d27d333a8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for parsing an IEMOCAP session by creating a dictionary that contains the sentence id as a key and the emotion as a value\n",
    "def get_IEMOCAP_session_emotions(location, session_id):\n",
    "\n",
    "    sentence_emotions = {}\n",
    "    \n",
    "    # Get all the emotion evaluation files from the specified session\n",
    "    emo_files_path = f\"{location}\\\\Session{session_id}\\\\dialog\\\\EmoEvaluation\\\\*.txt\"\n",
    "    emo_files = glob.glob(emo_files_path)\n",
    "    \n",
    "    for emo_file in emo_files:\n",
    "        with open(emo_file) as file:\n",
    "            file_contents = file.readlines()\n",
    "            \n",
    "            # Only get the lines with the file name and emotion\n",
    "            names_and_emotions = [x for x in file_contents if x.startswith(\"[\")]\n",
    "            \n",
    "            # Put all the file names and emotions in a dictionary\n",
    "            for line in names_and_emotions:\n",
    "                line_parts = line.split(\"\\t\")\n",
    "                sentence_emotions[line_parts[1]] = line_parts[2]\n",
    "\n",
    "                \n",
    "    # Remove all the entries that do not have an definitive emotion\n",
    "    culled_sentence_emotions = {k: v for k, v in sentence_emotions.items() if not v == \"xxx\" and not v == \"\"}\n",
    "    \n",
    "    # Remove all the entries that are not one of the four emotions recognised by the SpeechBrain model\n",
    "    culled_sentence_emotions = {k: v for k, v in culled_sentence_emotions.items() if v == \"neu\" or v == \"ang\" or v == \"sad\" or v == \"hap\"}\n",
    "    \n",
    "    return culled_sentence_emotions\n",
    "\n",
    "# Function for getting all the individual sentences wav files from the specified session\n",
    "def get_IEMOCAP_session_files(location, session_id):\n",
    "    files_path = f\"{location}\\\\Session{session_id}\\\\sentences\\\\wav\"\n",
    "    files = []\n",
    "\n",
    "    # For every subfolder in the session\n",
    "    for folder in os.listdir(files_path):\n",
    "        # List all the files in the subfolder\n",
    "        contents = os.listdir(f\"{location}\\\\Session{session_id}\\\\sentences\\\\wav\\\\{folder}\")\n",
    "        # Add all the .wav files to the list\n",
    "        files += [file for file in contents if file.endswith(\".wav\")]\n",
    "        \n",
    "    return files\n",
    "\n",
    "# Returns a list of all the files that are also in the emotions file\n",
    "def filter_appropriate_files(emotions, files, filtered=False):\n",
    "    if filtered:\n",
    "        return [item for item in files if item.rsplit(\"_\", 2)[0] in emotions]\n",
    "    else:\n",
    "        return [item for item in files if item[:-4] in emotions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7e43a-9e5e-4976-a082-08a1f7c99af4",
   "metadata": {},
   "source": [
    "## CSV Export Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e239f9f-d9ba-4329-8cc6-c216969af4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes a output path, file name, and results array and outputs the results array in CSV format to the output path in file name\n",
    "def results_to_csv(output_path, name, results):\n",
    "    # Get the absolute path to the new CSV file\n",
    "\n",
    "    # Create output path if it does not exist\n",
    "    if not os.path.exists(output_path):\n",
    "       os.makedirs(output_path)\n",
    "\n",
    "    csv_path = os.path.abspath(f\"{output_path}\\\\{name}.csv\")\n",
    "\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as new_file:\n",
    "        fieldnames = [\"Sentence\", \"Emotion\", \"Emotion_Guess\"]\n",
    "        writer = csv.DictWriter(new_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e3a13-7ea0-4c81-98ff-a9a7003bf2fe",
   "metadata": {},
   "source": [
    "## Accuracy Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71ed44-cd42-4816-b923-ce1bea21c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to calculate the accuracy of the results, with optional decimal number length parameter \n",
    "def calculate_accuracy_str(results, dec_len=10):\n",
    "    actual = [item[\"Emotion\"] for item in results]\n",
    "    predicted = [item[\"Emotion_Guess\"] for item in results]\n",
    "    score = accuracy_score(actual, predicted)\n",
    "    return f\"Accuracy: {score * 100:.{dec_len}f}%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23009f-e830-4069-9939-a6b29e775de1",
   "metadata": {},
   "source": [
    "## Model Initilization and Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1e79a-40ba-4efa-87bf-fe68fcef38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", \n",
    "                           pymodule_file=\"custom_interface.py\", \n",
    "                           classname=\"CustomEncoderWav2vec2Classifier\", \n",
    "                           run_opts={\"device\":\"cuda\"}) # Run on CUDA if you have a capable GPU. Remove parameter if you do not.\n",
    "\n",
    "# Function that takes a session id, a dictionary of files to the emotions expressed in those files, the files themselves\n",
    "# and a boolean for if the files are filtered, this is due to how the files are named.\n",
    "def run_classifier(location, session, emotions, files, filtered=False):\n",
    "    results = []\n",
    "    \n",
    "    # Count iterations for a nicer display\n",
    "    iterations = 1\n",
    "\n",
    "    # Process each file\n",
    "    for wav_file in files:\n",
    "        # Show progress text\n",
    "        progress = iterations/len(files)*100\n",
    "        print(\"\\rProcessing: {}, Progress: {:.2f}%\".format(wav_file, progress), end=\"\")\n",
    "\n",
    "        # Get folder .wav file is in\n",
    "        if filtered:\n",
    "            folder_name = wav_file.rsplit(\"_\", 3)[0]\n",
    "        else:\n",
    "            folder_name = wav_file.rsplit(\"_\", 1)[0]\n",
    "        \n",
    "        # Get path of current .wav file\n",
    "        file_path = os.path.join(f\"{location}\\\\Session{session}\\\\sentences\\\\wav\", folder_name, wav_file)\n",
    "        # Classify\n",
    "        out_prob, score, index, text_lab = classifier.classify_file(file_path)\n",
    "        \n",
    "        # Append data to results list\n",
    "        results.append({\n",
    "                \"Sentence\": wav_file,\n",
    "                \"Emotion\": emotions[wav_file[:-4]] if not filtered else emotions[wav_file.rsplit(\"_\", 2)[0]],\n",
    "                \"Emotion_Guess\": text_lab[0]\n",
    "            })\n",
    "\n",
    "        iterations += 1\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266188f0-8514-4663-907b-eca06833eef5",
   "metadata": {},
   "source": [
    "# 5.5 Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ef6b8-f111-422a-9f57-84d107f92d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_results = []\n",
    "\n",
    "# Loop through each session in the IEMOCAP database\n",
    "for i in range(1,2):\n",
    "    print(f\"Session {i}\")\n",
    "    # Get the appropriate files and corresponding emotional labels\n",
    "    session_emo = get_IEMOCAP_session_emotions(iemocap_location, i)\n",
    "    session_files = get_IEMOCAP_session_files(iemocap_location, i)\n",
    "\n",
    "    # Filter files to only keep the ones which are one of the 4 classifiable emotions\n",
    "    session_appropriate_files = filter_appropriate_files(session_emo, session_files)\n",
    "\n",
    "    # Run the classifier\n",
    "    results = run_classifier(iemocap_location, i, session_emo, session_appropriate_files)\n",
    "    \n",
    "    # Combine results with other data\n",
    "    combined_results = combined_results + results\n",
    "    \n",
    "    # Display classification stats per session\n",
    "    print(\"\\n\", calculate_accuracy_str(results, 2))\n",
    "    \n",
    "    # Print a nice line between sessions\n",
    "    term_size = os.get_terminal_size()\n",
    "    print('=' * term_size.columns)\n",
    "\n",
    "# Display overall performance stats\n",
    "print(\"Overall\")\n",
    "print(calculate_accuracy_str(combined_results, 2))\n",
    "\n",
    "# Export the results to a .csv file\n",
    "results_to_csv(results_location, \"IEMOCAP_Base\", combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9be021-10ec-4845-ac9a-bf2a447b9054",
   "metadata": {},
   "source": [
    "# 5.6 Audio Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5ebb1-854e-4adc-81e6-3d67e7542aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is a modified version of the code from this stack overflow post:\n",
    "# https://stackoverflow.com/questions/21871834/adding-effects-to-make-voice-sound-like-it-s-over-a-telephone\n",
    "\n",
    "# Creates a Butterworth filter from the low and high boundaries with a given order\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Applies the Butterworth filter \n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def bandpass_filter(buffer, lowcut, highcut, FRAME_RATE):\n",
    "    return butter_bandpass_filter(buffer, lowcut, highcut, FRAME_RATE, order=3)\n",
    "\n",
    "# Function that takes a list of files in the input path, filters them with the given low and high boundaries and outputs the files to the output path\n",
    "def filter_audio(low, high, sample, input_path, output_path, files):\n",
    "    if isdir(output_path) == False:\n",
    "        makedirs(output_path)\n",
    "    else:\n",
    "        shutil.rmtree(output_path)\n",
    "        makedirs(output_path)\n",
    "    \n",
    "    for file in files:\n",
    "        samplerate, data = wavfile.read(input_path + \"\\\\\" + file)\n",
    "        assert samplerate == sample\n",
    "        filtered = np.apply_along_axis(bandpass_filter, 0, data, lowcut=low, highcut=high, FRAME_RATE=sample).astype('int16')\n",
    "        wavfile.write(os.path.join(output_path, f'{file[:-4]}_l{low}_h{high}.wav'), samplerate, filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee40ac2-c94c-436e-bf3d-000333051bcf",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745ccb3-9c2c-40b6-a848-6d1577248552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_IEMOCAP_sentence_files(location, output_path, session_id, low_bound, high_bound):\n",
    "    files_path = f\"{location}\\\\Session{session_id}\\\\sentences\\\\wav\"\n",
    "    files = []\n",
    "\n",
    "    # Create \n",
    "    if not os.path.exists(output_path):\n",
    "       os.makedirs(output_path)\n",
    "    \n",
    "    for folder in os.listdir(files_path):\n",
    "        files = os.listdir(f\"{location}\\\\Session{session_id}\\\\sentences\\\\wav\\\\{folder}\")\n",
    "        wavfiles = [file for file in files if file.endswith('.wav')]\n",
    "        filter_audio(low_bound, high_bound, 16000, \n",
    "                     f\"{location}\\\\Session{session_id}\\\\sentences\\\\wav\\\\{folder}\", \n",
    "                     os.path.normpath(f\"{output_path}\\\\Session{session_id}\\\\sentences\\wav\\\\{folder}\"), wavfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193019d-ae54-4b3f-9cb5-05557903ec04",
   "metadata": {},
   "source": [
    "# 5.6.2 Baseline Filter Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5484d77-b656-44f7-a670-7109d0f7141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_iemocap_location = None # Where you want the filtered audio to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed0f01-60fc-4139-afd0-3e61bf6b7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_filtered_files(low_bound, high_bound):\n",
    "    combined_results = []\n",
    "    # Loop through each session in the IEMOCAP database\n",
    "    for i in range(1,6):\n",
    "        print(f\"Session {i}\")\n",
    "        \n",
    "        # Filter the audio files \n",
    "        print(\"Filtering audio files...\")\n",
    "        filter_IEMOCAP_sentence_files(iemocap_location, filtered_iemocap_location, i, low_bound, high_bound)\n",
    "        \n",
    "        # Get the appropriate files and corresponding emotional labels\n",
    "        session_emo = get_IEMOCAP_session_emotions(iemocap_location, i)\n",
    "        session_files = get_IEMOCAP_session_files(filtered_iemocap_location, i)\n",
    "    \n",
    "        # Filter files to only keep the ones which are one of the 4 classifiable emotions\n",
    "        session_appropriate_files = filter_appropriate_files(session_emo, session_files, filtered=True)\n",
    "    \n",
    "        # Run the classifier\n",
    "        results = run_classifier(filtered_iemocap_location, i, session_emo, session_appropriate_files, filtered=True)\n",
    "        \n",
    "        # Combine results with other data\n",
    "        combined_results = combined_results + results\n",
    "        \n",
    "        # Display classification stats per session\n",
    "        print(calculate_accuracy_str(results, 2))\n",
    "        \n",
    "        # Print a nice line between sessions\n",
    "        term_size = os.get_terminal_size()\n",
    "        print('=' * term_size.columns)\n",
    "    \n",
    "    # Display performance stats over whole database\n",
    "    print(\"Overall\")\n",
    "    print(calculate_accuracy_str(combined_results, 2))\n",
    "    \n",
    "    # Export the results to a .csv file\n",
    "    results_to_csv(results_location, f\"IEMOCAP_Filtered_l{low_bound}_h{high_bound}\", combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f39ec9-9089-4d84-a3c2-eacc5ebc01f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_bound = 1 # Lower bound has to be > 0\n",
    "high_bound = 7999 # Higher bound has to be < nyquist frequency (8000 in this case)\n",
    "\n",
    "classify_filtered_files(low_bound, high_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdb693-6eb9-4b59-b9b6-1b910eef4569",
   "metadata": {},
   "source": [
    "## Checking if file is filtered correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c4b81-732e-4d35-b9fd-871dea9f959d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_waveform(wav_file):\n",
    "    # Read the WAV file\n",
    "    samplerate, data = wavfile.read(wav_file)\n",
    "\n",
    "    # Compute spectrogram\n",
    "    f, t, Sxx = spectrogram(data, fs=samplerate)\n",
    "\n",
    "    # Plot spectrogram\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.pcolormesh(t, f, 10 * np.log10(Sxx))  # Plot in dB scale\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.title(f'Spectrogram of {wav_file}')\n",
    "    plt.colorbar(label='Power Spectral Density [dB]')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get handpicked file from the dataset and plot the spectrogram\n",
    "original_file = f\"{iemocap_location}\\\\Session1\\\\sentences\\\\wav\\\\Ses01F_impro01\\\\Ses01F_impro01_F000.wav\"\n",
    "plot_waveform(original_file)\n",
    "\n",
    "# Here we filter one handpicked file from the IEMOCAP dataset, to confirm the filter is applied correctly\n",
    "filter_audio(300, 3400, 16000, \n",
    "             f\"{iemocap_location}\\\\Session1\\\\sentences\\\\wav\\\\Ses01F_impro01\", \n",
    "             os.path.normpath(f\"{filtered_iemocap_location}\\\\Session1\\\\sentences\\wav\\\\Ses01F_impro01\"), [\"Ses01F_impro01_F000.wav\"])\n",
    "\n",
    "plot_waveform(f\"{filtered_iemocap_location}\\\\Session1\\\\sentences\\\\wav\\\\Ses01F_impro01\\\\Ses01F_impro01_F000_l300_h3400.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e4b3c-caf8-49d3-9927-102842499683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_bound = 300 \n",
    "high_bound = 3400 \n",
    "\n",
    "classify_filtered_files(low_bound, high_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fdac5-75fc-4da8-b732-a4be840e5007",
   "metadata": {},
   "source": [
    "# 5.7 Systematically Altering The Frequency Range on Audio Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ac128-e681-40dc-8330-29735f8b97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to systematically classify dataset with different frequency ranges\n",
    "# low_bound is an array with the lower and upper bound of the lower bound\n",
    "# high_bound is an array with the lower and upper bound of the higher bound\n",
    "# step_size is the step size between frequencies in these ranges\n",
    "def systematically_classify_filtered_files(low_bound, high_bound, step_size):\n",
    "    # Define the ranges for x (low) and y (high)\n",
    "    low_range = range(low_bound[0], low_bound[1], step_size)  \n",
    "    high_range = range(high_bound[0], high_bound[1], step_size)\n",
    "    \n",
    "    # Generate the coordinates making sure that the higher bound is not lower or equal to the lower bound\n",
    "    frequency_bands = [(x, y) for x in low_range for y in high_range if y > x]\n",
    "    \n",
    "    for step in frequency_bands:\n",
    "        combined_results = []\n",
    "        print(f\"Frequency Range between {step[0]} and {step[1]} Hz\")\n",
    "        # Loop through each session in the IEMOCAP database\n",
    "        for i in range(1,6):\n",
    "            print(f\"Session {i}\")\n",
    "            \n",
    "            # Filter the audio files \n",
    "            print(\"Filtering audio files...\")\n",
    "            filter_IEMOCAP_sentence_files(iemocap_location, filtered_iemocap_location, i, step[0], step[1])\n",
    "            \n",
    "            # Get the appropriate files and corresponding emotional labels\n",
    "            session_emo = get_IEMOCAP_session_emotions(iemocap_location, i)\n",
    "            session_files = get_IEMOCAP_session_files(filtered_iemocap_location, i)\n",
    "        \n",
    "            # Filter files to only keep the ones which are one of the 4 classifiable emotions\n",
    "            session_appropriate_files = filter_appropriate_files(session_emo, session_files, filtered=True)\n",
    "        \n",
    "            # Run the classifier\n",
    "            results = run_classifier(filtered_iemocap_location, i, session_emo, session_appropriate_files, filtered=True)\n",
    "            \n",
    "            # Combine results with other data\n",
    "            combined_results = combined_results + results\n",
    "            print(\"\\n\")\n",
    "        results_to_csv(results_location, f\"IEMOCAP_Filtered_l{step[0]}_h{step[1]}\", combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e44ae-742c-4f63-9f35-11762f189fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "systematically_classify_filtered_files([1, 4002], [1, 7999], 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
